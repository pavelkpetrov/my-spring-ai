server:
  port: 8080
  management:
    endpoints:
      web:
        exposure:
          include: health,info
  endpoint:
    health:
      show-details: when-authorized
# =============================================================================
# SPRING AI CONFIGURATION
# =============================================================================
spring:
  http:
    client:
      factory: simple
  application:
    name: chat-bot
  autoconfigure:
    exclude:
      - org.springframework.ai.model.chat.client.autoconfigure.ChatClientAutoConfiguration
  ai:
    vectorstore:
      chroma:
        collection-name: SpringAiCollection
        initialize-schema: true
        client:
          host: http://localhost
          port: 8001
    ollama:
      base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: ${OLLAMA_CHAT_MODEL:llama3.2}
          temperature: ${OLLAMA_CHAT_TEMPERATURE:0.8}
      init:
        pull-model-strategy: NEVER
      embedding:
        options:
          model: nomic-embed-text
    model:
      embedding: ollama
    chat:
      observations:
        include-completion: true
        include-prompt: true
        include-error-logging: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level:
    org.springframework.ai.chat.observation: DEBUG
    org.springframework.ai.client.observation: DEBUG
    com.my.spring.ai.bot: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.web.client: INFO
    root: INFO
  pattern:
    console: "%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
